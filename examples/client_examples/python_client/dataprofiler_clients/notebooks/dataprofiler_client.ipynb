{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Purpose\n",
    "The purpose of this notebook is to showcase the usage of the Federated Model Aggregation (FMA) Service's ready-made client.\n",
    "This is achieved by the usage of the fma_connect library's `webClient` class.\n",
    "\n",
    "The webclient class is composed of methods to abstract and make interation with the service consistent across different implementations.\n",
    "\n",
    "In this tutorial you will learn:\n",
    "* The basic usage of the webclient for the FMA service\n",
    "* The process of federated learning outlined by the FMA\n",
    "* Pulling the latest model weights from a specific experiment\n",
    "* Training a model on the client\n",
    "* Send updates to the FMA service with correctly formatted API calls\n",
    "* Pulling a model aggregate after it has been created for an experiment and repeating the training process\n",
    "\n",
    "The FMA service's API can be used with any model and any client so long as they are registered and can access the service with an API call.\n",
    "This particular tutorial uses Capital One's very own DataProfiler's DataLabeler model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overview of FMA Client Components\n",
    "The service assumes there are clients involved in your experiments that it does not initialize on its own.\n",
    "The client needs certain components to run model training and send model updates to the service.\n",
    "These components include:\n",
    "* Client Initialization\n",
    "  * Connect to Server\n",
    "  * Client Validation Dataset Generation\n",
    "* Model Initialization\n",
    "  * Setup Architecture\n",
    "  * Pull Model Weights\n",
    "* Model Training\n",
    "  * Training loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sklearn\n",
    "import dataprofiler as dp\n",
    "\n",
    "sys.path.insert(0, os.path.abspath( '../../../../../clients/python_client'))\n",
    "import fma_connect  # noqa: E402\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils import intialize_logger, numpify_array, jsonify_array, print_results, color_text\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from dataprofiler_utils.generation_scripts import generate_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Initialization\n",
    "Before we can do any federated learning, we must first initialize our client communication by registering with the FMA service for an experiment.\n",
    "This will allow us to push and pull model data to the FMA service itself."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to server\n",
    "The three variables needed for registration are:\n",
    "* `uuid_storage_path`: Unique ID for client\n",
    "  * Note this can be a pre-existing unique ID or an ID generated by the service\n",
    "* `federated_model_id`: The Unique ID of the model experiment in which the client will participate\n",
    "* `url`: The base URL for the service"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_storage_path = \"./uuid_temp_notebook.txt\"\n",
    "federated_model_id = 2\n",
    "url = \"http://localhost:8000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try registering with a pre-existing ID stored in a file\n",
    "try:\n",
    "    with open(uuid_storage_path) as f:\n",
    "        uuid = f.read()\n",
    "        print(f\"Connecting with {uuid} as UUID\")\n",
    "        client = fma_connect.WebClient(\n",
    "            federated_model_id=federated_model_id, url=url, uuid=uuid\n",
    "        )\n",
    "except FileNotFoundError:\n",
    "    print(\"Connecting without UUID\")\n",
    "    client = fma_connect.WebClient(federated_model_id=federated_model_id, url=url)\n",
    "finally:\n",
    "    client.register()\n",
    "    uuid = client.uuid\n",
    "    with open(uuid_storage_path, \"w+\") as f:\n",
    "        f.write(uuid)\n",
    "    print(f\"{uuid} stored as UUID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Validation Dataset Generation\n",
    "Now that we have our ID. We need to prep our client device to train the model.\n",
    "To do this we create a validation set that will be standard across all clients (we do this by passing a `validation_seed`).\n",
    "This dataset mimics the centralized \"golden\" validation set that would be a static collection of data on the server side in a federated learning use case.\n",
    "\n",
    "For this example we are going to use the following labels:\n",
    "* COOKIE\n",
    "* MAC_ADDRESS\n",
    "* SSN\n",
    "* DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_entity_names = [\"COOKIE\", \"MAC_ADDRESS\", \"SSN\", \"DATETIME\"]\n",
    "num_of_val_entities = 10\n",
    "validation_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "val_dataset_split = [\n",
    "    generate_sample(entity, num_of_val_entities, validation_seed)\n",
    "    for entity in val_entity_names\n",
    "]\n",
    "\n",
    "val_dataset = {\n",
    "    k: [item for dic in val_dataset_split for item in dic[k]]\n",
    "    for k in val_dataset_split[0]\n",
    "}\n",
    "\n",
    "# Get length of dataset for metrics generation\n",
    "length_of_dataset = 0\n",
    "for text in val_dataset[\"text\"]:\n",
    "    length_of_dataset += len(text)\n",
    "\n",
    "def create_label_char_array_from_entity_array(entity_array, _entities_dict, data_raw):\n",
    "    \"\"\"\n",
    "    Converts list with ranges of entities to a character level label list.\n",
    "\n",
    "    :param entity_array: List that holds entity ranges\n",
    "    :type entity_array: EntityArrayType\n",
    "    :param _entities_dict: Dict of entities and their indices\n",
    "    :type _entities_dict: EntitiesDictType\n",
    "    :param data_raw: the raw data used for creation of entity_array\n",
    "    :type data_raw: List[str]\n",
    "\n",
    "    :return: An character level label array (label per character)\n",
    "    :rtype: List[int]\n",
    "    \"\"\"\n",
    "    char_label_array = []\n",
    "    len_of_text = sum([len(text) for text in data_raw])\n",
    "    for text_section_index in range(len(entity_array)):\n",
    "        index = 0\n",
    "        for entity in entity_array[text_section_index]:\n",
    "            while index < entity[0]:\n",
    "                char_label_array.append(1)\n",
    "                index += 1\n",
    "            while index < entity[1]:\n",
    "                char_label_array.append(_entities_dict[str(entity[2])])\n",
    "                index += 1\n",
    "            while index < len(data_raw[text_section_index]):\n",
    "                char_label_array.append(1)\n",
    "                index += 1\n",
    "    # Final length check\n",
    "    while len(char_label_array) < len_of_text:\n",
    "        char_label_array.append(1)\n",
    "    return char_label_array"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model Architecture\n",
    "Now that we have the validation set created, we need to set up our client's model architecture.\n",
    "* **Pull the model**: Pull the DataLabeler model from the DataProfiler's library\n",
    "* **Set labels**: Set the labels we want to use for the model\n",
    "* **Set params**: Set the necessary params to ready the architecture for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = dp.DataLabeler(labeler_type=\"unstructured\", trainable=True)\n",
    "model_arch.set_labels(\n",
    "    {\n",
    "        \"PAD\": 0,\n",
    "        \"UNKNOWN\": 1,\n",
    "        \"DATETIME\": 2,\n",
    "        \"COOKIE\": 3,\n",
    "        \"MAC_ADDRESS\": 4,\n",
    "        \"SSN\": 5,\n",
    "    }\n",
    ")\n",
    "model_arch.model._reconstruct_model()\n",
    "\n",
    "# Setting post process params for human-readable format\n",
    "model_arch.set_params(\n",
    "    {\"postprocessor\": {\"output_format\": \"ner\", \"use_word_level_argmax\": True}}\n",
    ")\n",
    "\n",
    "# We create a version of the val data that will allow us to present some better quality,\n",
    "# human-readable results by highlighting the classifications the model makes.\n",
    "val_dataset_array = create_label_char_array_from_entity_array(val_dataset[\"entities\"], model_arch.label_mapping, val_dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Model Weights\n",
    "With the client's setup out of the way, we are finally ready to start our training process.\n",
    "\n",
    "* **Pull the latest model weights**:  We will pull model weights for our experiment using the `check_for_latest_model` function. This function pulls the latest weights (either latest model aggregate or artifact depending on which is the most recent).\n",
    "* **Set weights**: Set newly obtained weights to our model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = client.check_for_latest_model()\n",
    "numpify_array(model_obj[\"values\"])\n",
    "new_weights, base_aggregate = model_obj[\"values\"], model_obj[\"aggregate\"]\n",
    "model_arch.model._model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training Loop\n",
    "Finally, we are able to run our training loop.\n",
    "1. **Set training parameters**:\n",
    "    * Choose a singular entity to train on (for this example we are using `SSN`)\n",
    "    * Decide how many epochs we want to run before pushing the model to the service (1)\n",
    "    * Decide the number of federated training iterations we wish to participate in (10)\n",
    "2. **Gather training data**: Generate train data for each iteration with new randomly generated text injected with 200 SSN examples\n",
    "3. **Run training of Model**:\n",
    "    * Run training with the model weights provided by the service\n",
    "    * Send model updates to the service\n",
    "    * Pull model aggregates generated from service (aggregate of all involved clients)\n",
    "    * Evaluate newly aggregated model on the validation dataset\n",
    "    * Repeat 2 and 3\n",
    "\n",
    "Because the service is taking all the updates provided by the clients and aggregating their weights, the resultant weights are more generalized to all the data involved in the experiment rather than the data on which the client is currently trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_entity_names = \"SSN\"\n",
    "num_epochs = 1\n",
    "train_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(train_iterations): \n",
    "    # Client data collection\n",
    "    train_dataset = generate_sample(train_entity_names, 200)\n",
    "\n",
    "    # Client Train\n",
    "    model_arch.fit(x=train_dataset[\"text\"], y=train_dataset[\"entities\"], epochs=num_epochs)\n",
    "\n",
    "    # Inference for results\n",
    "    predictions = model_arch.predict(val_dataset[\"text\"])\n",
    "    color_text(val_dataset[\"text\"], predictions, model_arch.label_mapping)\n",
    "\n",
    "    # Send weights to service for aggregation\n",
    "    weights = model_arch.model._model.get_weights()\n",
    "    jsonify_array(weights)\n",
    "\n",
    "    client.send_update(client, weights, base_aggregate)\n",
    "\n",
    "    # Get new weights from service after aggregation\n",
    "    model_obj = client.check_for_latest_model()\n",
    "    while not model_obj:\n",
    "        print(\"Received None response...\")\n",
    "        time.sleep(5)\n",
    "        model_obj = client.check_for_latest_model()\n",
    "    print(\"Received valid response...\")\n",
    "\n",
    "    # Load aggregated weights to model\n",
    "    numpify_array(model_obj[\"values\"])\n",
    "    weights_updates = model_obj[\"values\"]\n",
    "    base_aggregate = model_obj[\"aggregate\"]\n",
    "    model_arch.model._model.set_weights(weights_updates)\n",
    "\n",
    "\n",
    "    # Run validation of new weights on client collected data\n",
    "    predictions = model_arch.predict(val_dataset[\"text\"])\n",
    "    pred_array = create_label_char_array_from_entity_array(\n",
    "        predictions[\"pred\"], model_arch.label_mapping, data_raw\n",
    "    )\n",
    "    val_results = {\n",
    "        \"f1_score\": sklearn.metrics.f1_score(\n",
    "            val_dataset_array, pred_array, average=None\n",
    "        ),\n",
    "        \"description\": sklearn.metrics.classification_report(\n",
    "            val_dataset_array, pred_array\n",
    "        ),\n",
    "    }\n",
    "    color_text(val_dataset[\"text\"], predictions, model_arch.label_mapping)\n",
    "\n",
    "    # Send validation results to service \n",
    "    resp = client.send_val_results(val_results, base_aggregate)\n",
    "    print(f\"Validation results sent! {resp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conclusion\n",
    "This was a very basic example of federated learning with the FMA service, but the concept of making federated learning easily accessible to any training pipeline is the base idea for the FMA service as a whole.The idea is to allow for all the pieces required for a federated learning process to be very simple additions to a pre-existing pipeline without subject matter expertise in federated learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}